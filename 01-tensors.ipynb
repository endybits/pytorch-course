{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "Tensors are a speciallized data structure (similar to an array or a matriz)\n",
    "In PyTorch, the tensors are used to encode the inputs and outputs of a model (as well as the model's parameters).\n",
    "\n",
    "In a easy way for developers, tensors are similar to numpy arrays `ndarray`, but they can also be used on a GPU or other accelerator hardware.\n",
    "\n",
    "\n",
    "Even, tensors and ndarrays can often share the same underlying memory, avoiding the need to copy data (see `torch.Tensor.numpy` and `torch.from_numpy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing a tensor\n",
    "\n",
    "Tensors can be initialized in a several ways:\n",
    "* Directly from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 4], [2, 5]]\n",
    "x_data = torch.tensor(data=data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Form a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From another tensor\n",
    "The new tensor retains the properties (shape, datatype) of the given tensor, unless explicitly overridden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "Random Tensor: \n",
      "tensor([[0.8553, 0.1360],\n",
      "        [0.6058, 0.4173]])\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "x_ones\n",
    "print(f\"Ones Tensor: \\n{x_ones}\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(f\"Random Tensor: \\n{x_rand}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With random or constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1]], dtype=torch.int8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (3, 3)\n",
    "torch.ones(shape, dtype=torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(size=shape, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attibutes of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      "tensor([[0.0575, 0.2794, 0.0374],\n",
      "        [0.9611, 0.0650, 0.5141],\n",
      "        [0.2174, 0.6723, 0.7554]])\n",
      "Tensor Shape: torch.Size([3, 3])\n",
      "Tensor Datatype: torch.float32\n",
      "Tensor Device: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(shape)\n",
    "print(f\"Tensor: \\n{tensor}\")\n",
    "print(f\"Tensor Shape: {tensor.shape}\")\n",
    "print(f\"Tensor Datatype: {tensor.dtype}\")\n",
    "print(f\"Tensor Device: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations on Tensors\n",
    "There are over 100 tensor operations, including arithmetic, linear algebra, matrix maniputation (slicing, indexing, transposing...), sampling and [more](https://pytorch.org/docs/stable/torch.html)\n",
    "\n",
    "It's recommended to use gpu for the operations, for a better performance than the cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available()) # if True, tensor = tensor.to('cuda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Indexing, Slicing, Joining, Mutating Ops (NumPy like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      "tensor([[0.5711, 0.5252, 0.2012, 0.2476],\n",
      "        [0.3713, 0.3154, 0.4144, 0.2392],\n",
      "        [0.4916, 0.0379, 0.6103, 0.0611],\n",
      "        [0.6992, 0.4027, 0.1402, 0.4776]])\n",
      "First row: \n",
      "tensor([0.5711, 0.5252, 0.2012, 0.2476])\n",
      "First column \n",
      "tensor([0.5711, 0.3713, 0.4916, 0.6992])\n",
      "Last row: \n",
      "tensor([0.6992, 0.4027, 0.1402, 0.4776])\n",
      "Last Column: \n",
      "tensor([0.2476, 0.2392, 0.0611, 0.4776])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(4, 4)\n",
    "print(f\"Tensor: \\n{tensor}\")\n",
    "print(f\"First row: \\n{tensor[0]}\")\n",
    "print(f\"First column \\n{tensor[:, 0]}\")\n",
    "print(f\"Last row: \\n{tensor[-1]}\")\n",
    "print(f\"Last Column: \\n{tensor[:, -1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3154, 0.4144],\n",
      "        [0.0379, 0.6103]])\n"
     ]
    }
   ],
   "source": [
    "# tensor [start:end, start:end]\n",
    "print(tensor[1:3, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Join tensors\n",
    "You can use `torch.cat` to concatenate a sequence of tensors, along a given dimension.\n",
    "Important: the dim is the axis to concatenate (0 is the row, 1 is the column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)\n",
    "t1 = torch.cat([tensor, tensor, tensor, tensor], dim=0)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Arithmetic operations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "y3 = torch.rand_like(tensor)\n",
    "\n",
    "torch.matmul(tensor, tensor.T, out=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# This computes the element-wise product. z1, z2, z3 will have the same value.\n",
    "z1 = tensor * tensor.T\n",
    "z2 = tensor.mul(tensor.T)\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor.T, out=z3)\n",
    "print(z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Single-element tensor__\n",
    "If you have a one-element tensor, for example by aggregating all values of a tensor into one value, you can convert it to a Python numerical value using `item()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__In-place operations__: operations that store the result into the operand are called _in-plece_. They are denoted by `_` suffix. For example: `x.copy_(y)` or `x.t_()` will change `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9., 8., 9., 9.],\n",
       "        [9., 8., 9., 9.],\n",
       "        [9., 8., 9., 9.],\n",
       "        [9., 8., 9., 9.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:, 1] = 0\n",
    "tensor.add_(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bridge with NumPy\n",
    "Tensor on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other.x\n",
    "\n",
    "##### Tensor to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "Numpy: \n",
      "[[1. 0. 1. 1.]\n",
      " [1. 0. 1. 1.]\n",
      " [1. 0. 1. 1.]\n",
      " [1. 0. 1. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:, 1] = 0\n",
    "print(f\"Tensor: \\n{tensor}\")\n",
    "n = tensor.numpy()\n",
    "print(f\"Numpy: \\n{n}\")\n",
    "torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any change on the tensor reflects on the NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      "tensor([[2., 1., 2., 2.],\n",
      "        [2., 1., 2., 2.],\n",
      "        [2., 1., 2., 2.],\n",
      "        [2., 1., 2., 2.]])\n",
      "Numpy: \n",
      "[[2. 1. 2. 2.]\n",
      " [2. 1. 2. 2.]\n",
      " [2. 1. 2. 2.]\n",
      " [2. 1. 2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "tensor.add_(1)\n",
    "print(f\"Tensor: \\n{tensor}\")\n",
    "print(f\"Numpy: \\n{n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NumPy array to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy: \n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "Tensor: \n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], dtype=torch.float64)\n",
      "Numpy: \n",
      "[[2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]]\n",
      "Tensor: \n",
      "tensor([[2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "n = np.ones((4, 4))\n",
    "t = torch.from_numpy(n)\n",
    "print(f\"Numpy: \\n{n}\")\n",
    "print(f\"Tensor: \\n{t}\")\n",
    "n = np.add(n, 1, out=n)\n",
    "print(f\"Numpy: \\n{n}\")\n",
    "print(f\"Tensor: \\n{t}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
