{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "Tensors are a speciallized data structure (similar to an array or a matriz)\n",
    "In PyTorch, the tensors are used to encode the inputs and outputs of a model (as well as the model's parameters).\n",
    "\n",
    "In a easy way for developers, tensors are similar to numpy arrays `ndarray`, but they can also be used on a GPU or other accelerator hardware.\n",
    "\n",
    "\n",
    "Even, tensors and ndarrays can often share the same underlying memory, avoiding the need to copy data (see `torch.Tensor.numpy` and `torch.from_numpy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing a tensor\n",
    "\n",
    "Tensors can be initialized in a several ways:\n",
    "* Directly from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 4], [2, 5]]\n",
    "x_data = torch.tensor(data=data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Form a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From another tensor\n",
    "The new tensor retains the properties (shape, datatype) of the given tensor, unless explicitly overridden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "Random Tensor: \n",
      "tensor([[0.4415, 0.6139],\n",
      "        [0.9234, 0.7112]])\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "x_ones\n",
    "print(f\"Ones Tensor: \\n{x_ones}\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(f\"Random Tensor: \\n{x_rand}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With random or constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1]], dtype=torch.int8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (3, 3)\n",
    "torch.ones(shape, dtype=torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(size=shape, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attibutes of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      "tensor([[0.1196, 0.8462, 0.2066],\n",
      "        [0.4413, 0.4624, 0.7521],\n",
      "        [0.4049, 0.8000, 0.6639]])\n",
      "Tensor Shape: torch.Size([3, 3])\n",
      "Tensor Datatype: torch.float32\n",
      "Tensor Device: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(shape)\n",
    "print(f\"Tensor: \\n{tensor}\")\n",
    "print(f\"Tensor Shape: {tensor.shape}\")\n",
    "print(f\"Tensor Datatype: {tensor.dtype}\")\n",
    "print(f\"Tensor Device: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations on Tensors\n",
    "There are over 100 tensor operations, including arithmetic, linear algebra, matrix maniputation (slicing, indexing, transposing...), sampling and [more](https://pytorch.org/docs/stable/torch.html)\n",
    "\n",
    "It's recommended to use gpu for the operations, for a better performance than the cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available()) # if True, tensor = tensor.to('cuda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Indexing, Slicing, Joining, Mutating Ops (NumPy like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      "tensor([[0.8397, 0.9427, 0.0916, 0.1292],\n",
      "        [0.0878, 0.7053, 0.3313, 0.7996],\n",
      "        [0.8941, 0.1002, 0.6931, 0.1012],\n",
      "        [0.2395, 0.0227, 0.7815, 0.5145]])\n",
      "First row: \n",
      "tensor([0.8397, 0.9427, 0.0916, 0.1292])\n",
      "First column \n",
      "tensor([0.8397, 0.0878, 0.8941, 0.2395])\n",
      "Last row: \n",
      "tensor([0.2395, 0.0227, 0.7815, 0.5145])\n",
      "Last Column: \n",
      "tensor([0.1292, 0.7996, 0.1012, 0.5145])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(4, 4)\n",
    "print(f\"Tensor: \\n{tensor}\")\n",
    "print(f\"First row: \\n{tensor[0]}\")\n",
    "print(f\"First column \\n{tensor[:, 0]}\")\n",
    "print(f\"Last row: \\n{tensor[-1]}\")\n",
    "print(f\"Last Column: \\n{tensor[:, -1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7053, 0.3313],\n",
      "        [0.1002, 0.6931]])\n"
     ]
    }
   ],
   "source": [
    "# tensor [start:end, start:end]\n",
    "print(tensor[1:3, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Join tensors\n",
    "You can use `torch.cat` to concatenate a sequence of tensors, along a given dimension.\n",
    "Important: the dim is the axis to concatenate (0 is the row, 1 is the column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)\n",
    "t1 = torch.cat([tensor, tensor, tensor, tensor], dim=0)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Arithmetic operations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "y3 = torch.rand_like(tensor)\n",
    "\n",
    "torch.matmul(tensor, tensor.T, out=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# This computes the element-wise product. z1, z2, z3 will have the same value.\n",
    "z1 = tensor * tensor.T\n",
    "z2 = tensor.mul(tensor.T)\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor.T, out=z3)\n",
    "print(z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Single-element tensor__\n",
    "If you have a one-element tensor, for example by aggregating all values of a tensor into one value, you can convert it to a Python numerical value using `item()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__In-place operations__: operations that store the result into the operand are called _in-plece_. They are denoted by `_` suffix. For example: `x.copy_(y)` or `x.t_()` will change `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9., 8., 9., 9.],\n",
       "        [9., 8., 9., 9.],\n",
       "        [9., 8., 9., 9.],\n",
       "        [9., 8., 9., 9.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:, 1] = 0\n",
    "tensor.add_(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bridge with NumPy\n",
    "Tensor on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other.x\n",
    "\n",
    "##### Tensor to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "Numpy: \n",
      "[[1. 0. 1. 1.]\n",
      " [1. 0. 1. 1.]\n",
      " [1. 0. 1. 1.]\n",
      " [1. 0. 1. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:, 1] = 0\n",
    "print(f\"Tensor: \\n{tensor}\")\n",
    "n = tensor.numpy()\n",
    "print(f\"Numpy: \\n{n}\")\n",
    "torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any change on the tensor reflects on the NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      "tensor([[2., 1., 2., 2.],\n",
      "        [2., 1., 2., 2.],\n",
      "        [2., 1., 2., 2.],\n",
      "        [2., 1., 2., 2.]])\n",
      "Numpy: \n",
      "[[2. 1. 2. 2.]\n",
      " [2. 1. 2. 2.]\n",
      " [2. 1. 2. 2.]\n",
      " [2. 1. 2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "tensor.add_(1)\n",
    "print(f\"Tensor: \\n{tensor}\")\n",
    "print(f\"Numpy: \\n{n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NumPy array to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy: \n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "Tensor: \n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], dtype=torch.float64)\n",
      "Numpy: \n",
      "[[2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]]\n",
      "Tensor: \n",
      "tensor([[2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "n = np.ones((4, 4))\n",
    "t = torch.from_numpy(n)\n",
    "print(f\"Numpy: \\n{n}\")\n",
    "print(f\"Tensor: \\n{t}\")\n",
    "n = np.add(n, 1, out=n)\n",
    "print(f\"Numpy: \\n{n}\")\n",
    "print(f\"Tensor: \\n{t}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
